# ============================================
# Requirements.txt - Proyecto Bibliométrico
# ============================================

# Core científico
numpy==1.24.3
pandas==2.0.3
scipy==1.11.1

# Procesamiento NLP
nltk==3.8.1
spacy==3.6.0
python-Levenshtein==0.21.1

# Machine Learning
scikit-learn==1.3.0

# Deep Learning / IA
torch==2.0.1
transformers==4.31.0
sentence-transformers==2.2.2

# Web Scraping
playwright==1.40.0  # En lugar de selenium
beautifulsoup4==4.12.2
requests==2.31.0

# Parsers bibliográficos
rispy==4.0.0
bibtexparser==1.4.0

# Visualizaciones
matplotlib==3.7.2
seaborn==0.12.2
plotly==5.16.1
kaleido==0.2.1  # Para exportar plotly a imágenes
wordcloud==1.9.2

# Exportación PDF
reportlab==4.0.4
PyPDF2==3.0.1
weasyprint==59.0

# Geoespacial (para mapas)
geopandas==0.13.2
folium==0.14.0

# Configuración
pyyaml==6.0.1

# Utilidades
tqdm==4.66.1  # Barras de progreso
colorlog==6.7.0  # Logging con colores
python-dotenv==1.0.0  # Variables de entorno

# Jupyter (para notebooks)
jupyter==1.0.0
ipykernel==6.25.0
ipywidgets==8.1.0

# Testing (opcional)
pytest==7.4.0
pytest-cov==4.1.0

# Linting (opcional)
black==23.7.0
flake8==6.1.0

# ============================================
# NOTAS DE INSTALACIÓN:
# ============================================
#
# 1. Crear entorno virtual:
#    python -m venv venv
#    source venv/bin/activate  # Linux/Mac
#    venv\Scripts\activate     # Windows
#
# 2. Instalar dependencias:
#    pip install -r requirements.txt
#
# 3. Descargar modelo de spaCy:
#    python -m spacy download en_core_web_sm
#
# 4. Descargar datos NLTK:
#    python -c "import nltk; nltk.download('stopwords'); nltk.download('punkt')"
#
# 5. Instalar ChromeDriver para Selenium:
#    - Linux: sudo apt-get install chromium-chromedriver
#    - Mac: brew install chromedriver
#    - Windows: Descargar desde https://chromedriver.chromium.org/
#
# ============================================